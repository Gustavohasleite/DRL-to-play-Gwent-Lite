# Gwent IA

Este repositÃ³rio contÃ©m o desenvolvimento de agentes de **Deep Reinforcement Learning (DRL)** para o **GwentLite**, uma versÃ£o customizada e simplificada do jogo de cartas Gwent. 

O projeto foca em treinar redes neurais capazes de gerenciar vantagem de cartas, decidir o momento ideal de passar a rodada e utilizar efeitos especiais estrategicamente em uma disputa de melhor de trÃªs.

---

## ğŸš€ Treinamento em Supercomputador

Os modelos presentes neste repositÃ³rio foram treinados em um ambiente de computaÃ§Ã£o de alto desempenho (**Supercomputador/Cluster Slurm**), permitindo a exploraÃ§Ã£o de arquiteturas complexas e grandes volumes de experiÃªncias (Experience Replay).

**Destaques do ambiente:**
- **Hardware:** GPUs de alto desempenho.
- **Software:** TensorFlow acelerado com CUDA 12.6 e XLA.
- **Escalabilidade:** Uso de gerenciador de tarefas Slurm para treinamentos de longa duraÃ§Ã£o (10.000+ episÃ³dios).

---

## ğŸƒ GwentLite: Regras do Jogo

O **GwentLite** simplifica a mecÃ¢nica do Gwent original para focar na lÃ³gica de decisÃ£o:

- **Cartas:** Representadas por nÃºmeros que indicam seu poder.
- **Cartas Especiais:**
    - **[3] Muster:** Joga todas as outras cÃ³pias de "3" do seu deck automaticamente.
    - **[6] Spy:** DÃ¡ 6 pontos ao oponente, mas permite que vocÃª compre 1 carta extra.
    - **[9] Scorch:** Adiciona 9 pontos ao seu lado e remove atÃ© 5 pontos do oponente.
- **Cartas Comuns:** Apenas adicionam seu valor nominal ao placar.
- **Objetivo:** Vencer 2 de 3 rodadas acumulando mais pontos que o adversÃ¡rio.

---

## ğŸ§  Agentes DisponÃ­veis

- **DQN (Deep Q-Network):** Agente base com rede neural profunda.
- **DDQN (Double DQN):** Melhora a estabilidade ao evitar a superestimaÃ§Ã£o de valores Q.
- **Dueling DQN:** Arquitetura que separa o valor do estado da vantagem da aÃ§Ã£o, ideal para jogos com estados de valor similar.
- **Minimax:** Um baseline clÃ¡ssico que utiliza busca em Ã¡rvore com profundidade limitada para decisÃµes tÃ¡ticas.

---

## ğŸ“‚ Estrutura de Arquivos

- `agents/`: ImplementaÃ§Ãµes das arquiteturas de IA.
- `games/`: O motor do jogo `GwentLite.py`.
- `models/`: Pesos das redes neurais treinadas (ex: `DDQN_v2_10000.weights.h5`).
- `metrics/`: Logs de performance, ELO e resultados de torneios.
- `training_scripts/`: Scripts usados para treinar os agentes no cluster.
- `jogar_vs_ia.py`: Interface para desafiar um dos modelos treinados.

---

## ğŸ’¾ Modelos Treinados

O repositÃ³rio inclui modelos prontos para uso na pasta `models/`, treinados por 10.000 episÃ³dios cada:

- **`DQN_v1_10000.weights.h5`**: Agente DQN base treinado com recompensas padrÃ£o.
- **`DDQN_v2_10000.weights.h5`**: Agente Double DQN treinado com *Reward Shaping* para decisÃµes mais agressivas e eficientes.

---

## ğŸ› ï¸ Como Utilizar

### Requisitos
- Python 3.12+
- TensorFlow 2.16+
- NumPy

### Jogar contra a IA
Para testar suas estratÃ©gias contra o modelo treinado em supercomputador:
```bash
python jogar_vs_ia.py
```

### Executar Torneios
Para colocar os diferentes agentes para se enfrentarem:
```bash
python training_scripts/run_tournament_v2.py
```
